{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "https://koreapy.tistory.com/1562\n",
    "https://koreapy.tistory.com/1561"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nibabel as nib\n",
    "import numpy as np\n",
    "import glob\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\parkm\\AppData\\Local\\Temp\\ipykernel_30960\\3986616899.py:5: DeprecationWarning: Please use `map_coordinates` from the `scipy.ndimage` namespace, the `scipy.ndimage.interpolation` namespace is deprecated.\n",
      "  from scipy.ndimage.interpolation import map_coordinates\n"
     ]
    }
   ],
   "source": [
    "from collections import OrderedDict\n",
    "from copy import deepcopy\n",
    "\n",
    "from skimage.transform import resize\n",
    "from scipy.ndimage.interpolation import map_coordinates\n",
    "import numpy as np\n",
    "from multiprocessing.pool import Pool\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\parkm\\AppData\\Local\\Temp\\ipykernel_30960\\2253951005.py:1: DeprecationWarning: Please use `map_coordinates` from the `scipy.ndimage` namespace, the `scipy.ndimage.interpolation` namespace is deprecated.\n",
      "  from scipy.ndimage.interpolation import map_coordinates\n"
     ]
    }
   ],
   "source": [
    "from scipy.ndimage.interpolation import map_coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "adc = r'C:\\Users\\parkm\\Desktop\\github\\ANALYSIS-NIFTI-FOR-DEEP-LEARNING\\data\\task1.stroke_multimodal\\dataset-ISLES22^public^unzipped^version\\rawdata\\sub-strokecase0003\\ses-0001\\sub-strokecase0003_ses-0001_adc.nii.gz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "dwi = r'C:\\Users\\parkm\\Desktop\\github\\ANALYSIS-NIFTI-FOR-DEEP-LEARNING\\data\\task1.stroke_multimodal\\dataset-ISLES22^public^unzipped^version\\rawdata\\sub-strokecase0003\\ses-0001\\sub-strokecase0003_ses-0001_dwi.nii.gz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "flair = r'C:\\Users\\parkm\\Desktop\\github\\ANALYSIS-NIFTI-FOR-DEEP-LEARNING\\data\\task1.stroke_multimodal\\dataset-ISLES22^public^unzipped^version\\rawdata\\sub-strokecase0003\\ses-0001\\sub-strokecase0003_ses-0001_flair.nii.gz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "adc_nii = nib.load(adc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(112, 112, 72)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adc_nii.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(112, 112, 72)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dwi_nii = nib.load(dwi)\n",
    "dwi_nii.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(281, 352, 352)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flair_nii = nib.load(flair)\n",
    "flair_nii.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchio as tio\n",
    "\n",
    "image = tio.ScalarImage(flair)\n",
    "transform = tio.CropOrPad((112,112,72))\n",
    "output = transform(image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 112, 112, 72)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torchio.data.image.ScalarImage"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class PreprocessorFor3D_LeaveOriginalZSpacing(GenericPreprocessor):\n",
    "    \"\"\"\n",
    "    3d_lowres and 3d_fullres are not resampled along z!\n",
    "    \"\"\"\n",
    "    def resample_and_normalize(self, data, target_spacing, properties, seg=None, force_separate_z=None):\n",
    "        \"\"\"\n",
    "        if target_spacing[0] is None or nan we use original_spacing_transposed[0] (no resampling along z)\n",
    "        :param data:\n",
    "        :param target_spacing:\n",
    "        :param properties:\n",
    "        :param seg:\n",
    "        :param force_separate_z:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        original_spacing_transposed = np.array(properties[\"original_spacing\"])[self.transpose_forward]\n",
    "        before = {\n",
    "            'spacing': properties[\"original_spacing\"],\n",
    "            'spacing_transposed': original_spacing_transposed,\n",
    "            'data.shape (data is transposed)': data.shape\n",
    "        }\n",
    "\n",
    "        # remove nans\n",
    "        data[np.isnan(data)] = 0\n",
    "        target_spacing = deepcopy(target_spacing)\n",
    "        if target_spacing[0] is None or np.isnan(target_spacing[0]):\n",
    "            target_spacing[0] = original_spacing_transposed[0]\n",
    "        #print(target_spacing, original_spacing_transposed)\n",
    "        data, seg = resample_patient(data, seg, np.array(original_spacing_transposed), target_spacing, 3, 1,\n",
    "                                     force_separate_z=force_separate_z, order_z_data=0, order_z_seg=0,\n",
    "                                     separate_z_anisotropy_threshold=self.resample_separate_z_anisotropy_threshold)\n",
    "        after = {\n",
    "            'spacing': target_spacing,\n",
    "            'data.shape (data is resampled)': data.shape\n",
    "        }\n",
    "        st = \"before:\" + str(before) + '\\nafter' + str(after) + \"\\n\"\n",
    "        print(st)\n",
    "\n",
    "        if seg is not None:  # hippocampus 243 has one voxel with -2 as label. wtf?\n",
    "            seg[seg < -1] = 0\n",
    "\n",
    "        properties[\"size_after_resampling\"] = data[0].shape\n",
    "        properties[\"spacing_after_resampling\"] = target_spacing\n",
    "        use_nonzero_mask = self.use_nonzero_mask\n",
    "\n",
    "        assert len(self.normalization_scheme_per_modality) == len(data), \"self.normalization_scheme_per_modality \" \\\n",
    "                                                                         \"must have as many entries as data has \" \\\n",
    "                                                                         \"modalities\"\n",
    "        assert len(self.use_nonzero_mask) == len(data), \"self.use_nonzero_mask must have as many entries as data\" \\\n",
    "                                                        \" has modalities\"\n",
    "\n",
    "        for c in range(len(data)):\n",
    "            scheme = self.normalization_scheme_per_modality[c]\n",
    "            if scheme == \"CT\":\n",
    "                # clip to lb and ub from train data foreground and use foreground mn and sd from training data\n",
    "                assert self.intensityproperties is not None, \"ERROR: if there is a CT then we need intensity properties\"\n",
    "                mean_intensity = self.intensityproperties[c]['mean']\n",
    "                std_intensity = self.intensityproperties[c]['sd']\n",
    "                lower_bound = self.intensityproperties[c]['percentile_00_5']\n",
    "                upper_bound = self.intensityproperties[c]['percentile_99_5']\n",
    "                data[c] = np.clip(data[c], lower_bound, upper_bound)\n",
    "                data[c] = (data[c] - mean_intensity) / std_intensity\n",
    "                if use_nonzero_mask[c]:\n",
    "                    data[c][seg[-1] < 0] = 0\n",
    "            elif scheme == \"CT2\":\n",
    "                # clip to lb and ub from train data foreground, use mn and sd form each case for normalization\n",
    "                assert self.intensityproperties is not None, \"ERROR: if there is a CT then we need intensity properties\"\n",
    "                lower_bound = self.intensityproperties[c]['percentile_00_5']\n",
    "                upper_bound = self.intensityproperties[c]['percentile_99_5']\n",
    "                mask = (data[c] > lower_bound) & (data[c] < upper_bound)\n",
    "                data[c] = np.clip(data[c], lower_bound, upper_bound)\n",
    "                mn = data[c][mask].mean()\n",
    "                sd = data[c][mask].std()\n",
    "                data[c] = (data[c] - mn) / sd\n",
    "                if use_nonzero_mask[c]:\n",
    "                    data[c][seg[-1] < 0] = 0\n",
    "            elif scheme == 'noNorm':\n",
    "                pass\n",
    "            else:\n",
    "                if use_nonzero_mask[c]:\n",
    "                    mask = seg[-1] >= 0\n",
    "                else:\n",
    "                    mask = np.ones(seg.shape[1:], dtype=bool)\n",
    "                data[c][mask] = (data[c][mask] - data[c][mask].mean()) / (data[c][mask].std() + 1e-8)\n",
    "                data[c][mask == 0] = 0\n",
    "        return data, seg, properties\n",
    "\n",
    "    def run(self, target_spacings, input_folder_with_cropped_npz, output_folder, data_identifier,\n",
    "            num_threads=default_num_threads, force_separate_z=None):\n",
    "        for i in range(len(target_spacings)):\n",
    "            target_spacings[i][0] = None\n",
    "        super().run(target_spacings, input_folder_with_cropped_npz, output_folder, data_identifier,\n",
    "                    default_num_threads, force_separate_z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resample_data_or_seg(data, new_shape, is_seg, axis=None, order=3, do_separate_z=False, order_z=0):\n",
    "    \"\"\"\n",
    "    separate_z=True will resample with order 0 along z\n",
    "    :param data:\n",
    "    :param new_shape:\n",
    "    :param is_seg:\n",
    "    :param axis:\n",
    "    :param order:\n",
    "    :param do_separate_z:\n",
    "    :param order_z: only applies if do_separate_z is True\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    assert len(data.shape) == 4, \"data must be (c, x, y, z)\"\n",
    "    assert len(new_shape) == len(data.shape) - 1\n",
    "    if is_seg:\n",
    "        resize_fn = resize_segmentation\n",
    "        kwargs = OrderedDict()\n",
    "    else:\n",
    "        resize_fn = resize\n",
    "        kwargs = {'mode': 'edge', 'anti_aliasing': False}\n",
    "    dtype_data = data.dtype\n",
    "    shape = np.array(data[0].shape)\n",
    "    new_shape = np.array(new_shape)\n",
    "    if np.any(shape != new_shape):\n",
    "        data = data.astype(float)\n",
    "        if do_separate_z:\n",
    "            print(\"separate z, order in z is\", order_z, \"order inplane is\", order)\n",
    "            assert len(axis) == 1, \"only one anisotropic axis supported\"\n",
    "            axis = axis[0]\n",
    "            if axis == 0:\n",
    "                new_shape_2d = new_shape[1:]\n",
    "            elif axis == 1:\n",
    "                new_shape_2d = new_shape[[0, 2]]\n",
    "            else:\n",
    "                new_shape_2d = new_shape[:-1]\n",
    "\n",
    "            reshaped_final_data = []\n",
    "            for c in range(data.shape[0]):\n",
    "                reshaped_data = []\n",
    "                for slice_id in range(shape[axis]):\n",
    "                    if axis == 0:\n",
    "                        reshaped_data.append(resize_fn(data[c, slice_id], new_shape_2d, order, **kwargs).astype(dtype_data))\n",
    "                    elif axis == 1:\n",
    "                        reshaped_data.append(resize_fn(data[c, :, slice_id], new_shape_2d, order, **kwargs).astype(dtype_data))\n",
    "                    else:\n",
    "                        reshaped_data.append(resize_fn(data[c, :, :, slice_id], new_shape_2d, order, **kwargs).astype(dtype_data))\n",
    "                reshaped_data = np.stack(reshaped_data, axis)\n",
    "                if shape[axis] != new_shape[axis]:\n",
    "\n",
    "                    # The following few lines are blatantly copied and modified from sklearn's resize()\n",
    "                    rows, cols, dim = new_shape[0], new_shape[1], new_shape[2]\n",
    "                    orig_rows, orig_cols, orig_dim = reshaped_data.shape\n",
    "\n",
    "                    row_scale = float(orig_rows) / rows\n",
    "                    col_scale = float(orig_cols) / cols\n",
    "                    dim_scale = float(orig_dim) / dim\n",
    "\n",
    "                    map_rows, map_cols, map_dims = np.mgrid[:rows, :cols, :dim]\n",
    "                    map_rows = row_scale * (map_rows + 0.5) - 0.5\n",
    "                    map_cols = col_scale * (map_cols + 0.5) - 0.5\n",
    "                    map_dims = dim_scale * (map_dims + 0.5) - 0.5\n",
    "\n",
    "                    coord_map = np.array([map_rows, map_cols, map_dims])\n",
    "                    if not is_seg or order_z == 0:\n",
    "                        reshaped_final_data.append(map_coordinates(reshaped_data, coord_map, order=order_z,\n",
    "                                                                   mode='nearest')[None].astype(dtype_data))\n",
    "                    else:\n",
    "                        unique_labels = np.unique(reshaped_data)\n",
    "                        reshaped = np.zeros(new_shape, dtype=dtype_data)\n",
    "\n",
    "                        for i, cl in enumerate(unique_labels):\n",
    "                            reshaped_multihot = np.round(\n",
    "                                map_coordinates((reshaped_data == cl).astype(float), coord_map, order=order_z,\n",
    "                                                mode='nearest'))\n",
    "                            reshaped[reshaped_multihot > 0.5] = cl\n",
    "                        reshaped_final_data.append(reshaped[None].astype(dtype_data))\n",
    "                else:\n",
    "                    reshaped_final_data.append(reshaped_data[None].astype(dtype_data))\n",
    "            reshaped_final_data = np.vstack(reshaped_final_data)\n",
    "        else:\n",
    "            print(\"no separate z, order\", order)\n",
    "            reshaped = []\n",
    "            for c in range(data.shape[0]):\n",
    "                reshaped.append(resize_fn(data[c], new_shape, order, **kwargs)[None].astype(dtype_data))\n",
    "            reshaped_final_data = np.vstack(reshaped)\n",
    "        return reshaped_final_data.astype(dtype_data)\n",
    "    else:\n",
    "        print(\"no resampling necessary\")\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 ('miccai')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ad0e9ecde611ae35305dd4ed9aae66f2cfc24eed9b69d21cc1d6de69b29a2e73"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
